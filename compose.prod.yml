services:
  webapp:
    container_name: webapp-prod
    restart: unless-stopped
    image: ft_transcendence:prod
    build:
      context: .
      dockerfile: Dockerfile
    command: bun start
    healthcheck:
      test: 
        - CMD-SHELL
        - /bin/bash
        - -c
        - |
          response=`curl -s -w "%{http_code}" http://localhost:3000/api/health`
          status_code=$${response: -3}
          if [ "$$status_code" -ne 200 ]; then
            echo healthcheck failed: webapp returned $$status_code: $$response
            exit 1
          fi
          
          echo "webapp is healthy"
          exit 0
      interval: 1s
      timeout: 5s
      retries: 10
    depends_on:
      db:
        condition: service_healthy
      presence-db:
        condition: service_healthy
      storage:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    environment:
      - NODE_ENV=production
      - HOST=${WEBAPP_HOST:?}
      - DATABASE_URL=postgres://${POSTGRES_USER:?}:${POSTGRES_PASSWORD:?}@db:5432/app
      - PRESENCE_DB_URL=redis://presence-db:6379
      - STORAGE_PUBLIC_ENDPOINT=https://${STORAGE_HOST:?}
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:?}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:?}
    networks:
      - proxy
      - internal

  proxy:
    container_name: proxy-prod
    restart: unless-stopped
    depends_on:
      webapp:
        condition: service_healthy
      storage:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: nginx:latest
    environment:
      WEBAPP_HOST: ${WEBAPP_HOST:?}
      STORAGE_HOST: ${STORAGE_HOST:?}
      KIBANA_HOST: ${KIBANA_HOST:?}
    volumes:
      - ./nginx/entrypoints/:/docker-entrypoint.d/99-user-scripts/:ro
      - ./nginx/templates/:/etc/nginx/templates/:ro
      - .secrets/ssl_certs:/etc/nginx/ssl/
    ports:
      - "80:80"
      - "443:443"
    healthcheck:
      test: 
        - CMD-SHELL
        - /bin/bash
        - -c
        - |
          response=`curl -s -w "%{http_code}" https://$$WEBAPP_HOST/api/health`
          status_code=$${response: -3}
          if [ "$$status_code" -ne 200 ]; then
            echo healthcheck failed: webapp returned $$status_code: $$response
            exit 1
          fi

          response=`curl -s -w "%{http_code}" https://$$STORAGE_HOST/minio/health/live`
          status_code=$${response: -3}
          if [ "$$status_code" -ne 200 ]; then
            echo healthcheck failed: storage returned $$status_code: $$response
            exit 1
          fi

          response=`curl -s -w "%{http_code}" https://$$KIBANA_HOST`
          status_code=$${response: -3}
          if [ "$$status_code" -ne 302 ] && [ "$$status_code" -ne 200 ]; then
            echo healthcheck failed: kibana returned $$status_code: $$response
            exit 1
          fi

          echo "all services healthy"
          exit 0
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - proxy

  db:
    container_name: db-prod
    restart: unless-stopped
    image: postgres:18
    environment:
      POSTGRES_USER: ${POSTGRES_USER:?}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?}
      POSTGRES_DB: app
    volumes:
      - db_data:/var/lib/postgresql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - internal

  storage:
    container_name: storage-prod
    restart: unless-stopped
    image: ft_transcendence:minio
    build:
      context: ./submodules/minio
      dockerfile: ../../Dockerfile.minio
    command: server /data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 1s
      timeout: 5s
      retries: 10
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:?}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:?}
    volumes:
      - storage_data:/data
    networks:
      - proxy
      - internal

  presence-db:
    container_name: redis-prod
    restart: unless-stopped
    image: redis:8.4
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "ping"]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - internal
  
  migrate:
    container_name: migrate-prod
    image: ft_transcendence:migrate
    build:
      context: .
      dockerfile: Dockerfile
      target: migrate-env
    depends_on:
      db:
        condition: service_healthy
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgres://${POSTGRES_USER:?}:${POSTGRES_PASSWORD:?}@db:5432/app
    networks:
      - internal
  
  setup-elastic:
    container_name: setup-elastic-prod
    depends_on:
      es01:
        condition: service_started
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - certs-elastic:/usr/share/elasticsearch/config/certs
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: es01\n"\
          "    dns:\n"\
          "      - es01\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find config/certs -type d -exec chmod 750 \{\} \;;
        find config/certs -type f -exec chmod 640 \{\} \;;
        find config/certs -type f -name "*.crt" -exec chmod 644 \{\} \;;
        echo "Waiting for Elasticsearch availability";
        until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120
    networks:
      - internal
  
  es01:
    container_name: elasticsearch-prod
    restart: unless-stopped
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - certs-elastic:/usr/share/elasticsearch/config/certs
      - es01-data-prod:/usr/share/elasticsearch/data
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es01/es01.key
      - xpack.security.http.ssl.certificate=certs/es01/es01.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es01/es01.key
      - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=basic
      - xpack.ml.use_auto_machine_memory_percent=true
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - internal

  kibana:
    container_name: kibana-prod
    depends_on:
      es01:
        condition: service_healthy
    restart: unless-stopped
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    volumes:
      - certs-elastic:/usr/share/kibana/config/certs
      - kibana-data-prod:/usr/share/kibana/data
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=https://es01:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
    mem_limit: ${MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:${KIBANA_PORT:?} | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - proxy
      - internal

  setup-logstash-jdbc:
    container_name: setup-logstash-jdbc-prod
    image: curlimages/curl:8.5.0
    user: "0"
    command:
      - sh
      - -c
      - |
        set -eu
        JAR=/jdbc/postgresql.jar
        if [ -f "$${JAR}" ]; then
          echo "PostgreSQL JDBC already present"
          exit 0
        fi
        echo "Downloading PostgreSQL JDBC driver..."
        curl -fsSL -o "$${JAR}" https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.4/postgresql-42.7.4.jar
        chmod 644 "$${JAR}"
        echo "Done"
    volumes:
      - logstash-jdbc:/jdbc
    networks:
      - internal

  logstash:
    container_name: logstash-prod
    depends_on:
      es01:
        condition: service_healthy
      db:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
      setup-logstash-jdbc:
        condition: service_completed_successfully
    restart: unless-stopped
    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
    user: root
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER:?}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:?}
    volumes:
      - certs-elastic:/usr/share/logstash/config/certs:ro
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - logstash-jdbc:/usr/share/logstash/vendor/jar/jdbc:ro
    networks:
      - internal

  setup-kibana-data-views:
    container_name: setup-kibana-data-views-prod
    image: curlimages/curl:8.5.0
    depends_on:
      kibana:
        condition: service_healthy
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    volumes:
      - ./elk/kibana/setup-data-views.sh:/scripts/setup-data-views.sh:ro
    command: ["sh", "/scripts/setup-data-views.sh"]
    networks:
      - internal

  import-kibana-dashboards:
    container_name: import-kibana-dashboards-prod
    image: curlimages/curl:8.5.0
    depends_on:
      kibana:
        condition: service_healthy
      setup-kibana-data-views:
        condition: service_completed_successfully
    environment:
      - KIBANA_PROTOCOL=http
      - KIBANA_HOST=kibana:${KIBANA_PORT:?}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:?}
    volumes:
      - ./elk/kibana/import-dashboards.sh:/scripts/import-dashboards.sh:ro
      - ./elk/kibana/dashboards:/scripts/dashboards:ro
    command: ["sh", "/scripts/import-dashboards.sh", "/scripts/dashboards/dashboards.ndjson"]
    networks:
      - internal

networks:
  proxy:
  internal:
  
volumes:
  db_data:
  storage_data:
  es01-data-prod:
  kibana-data-prod:
  certs-elastic:
  logstash-jdbc:
